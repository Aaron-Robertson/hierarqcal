{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dynamic QCNNs\n",
    "\n",
    "This notebook shows how to use the `dynamic_qcnn` package to generate Quantum Convolutional Neural Networks (QCNNs) using [cirq](https://quantumai.google/cirq) and [tensorflow quantum](https://www.tensorflow.org/quantum/overview). The core functionality is two primitive operations or cells (`QConv` for convolutions and `QPool` for pooling) which can be dynamically stacked ontop each to create a full QCNN. Then there are functions like `binary_tree_r` to generate families QCNNs using this core functionality. The tool helps with the following:\n",
    " - **Architecture search space design:** it's easy to define and generate families of QCNNs that capture different design motifs such that a system can greedily/intelligently search through them.\n",
    " - **Accessibility and usability of the QCNN:** the tool abstracts away a lot of details enabling different levels of interaction for QCNN modelling. It's also library agnostic and can be used with any QML library.\n",
    "\n",
    "The example shown is a binary classification model that distinguishes between two musical genres using the well known GTZAN dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "*A cute robot building itself with artifical intelligence, pencil drawing -  generated with* [Dall$\\cdot$E 2](https://openai.com/dall-e-2/)\n",
    "\n",
    "<img src=\"../img/DALLÂ·E 2022-08-17 11.48.32 - A cute robot building itself with artifical intelligence, pencil drawing.png\" alt=\"drawing\" width=\"200\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import sympy\n",
    "import numpy as np\n",
    "from collections import namedtuple\n",
    "import pandas as pd\n",
    "import cirq\n",
    "import tensorflow as tf\n",
    "import tensorflow_quantum as tfq\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# visualization tools\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimental setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset contains statistics from 1000 audio tracks, each being a 30-second recording of some song. Each song is given a label of one of the following ten musical genres: **blues, classical, country, disco, hiphop, jazz, metal, pop, reggae, rock**. See [marsyas](https://github.com/marsyas/website/blob/master/downloads/data-sets.rst) and [kaggle](https://www.kaggle.com/datasets/andradaolteanu/gtzan-dataset-music-genre-classification) for more info.\n",
    "\n",
    "We'll build a model to distinguish **rock** from **reggae**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify data path\n",
    "path = \"../data/gtzan_30s_stats.csv\"\n",
    "# Specify genres to build classification model from, options are:\n",
    "# blues, classical, country, disco, hiphop, jazz, metal, pop, reggae, rock\n",
    "target_pair = [\"rock\", \"reggae\"]\n",
    "# Read data\n",
    "raw = pd.read_csv(path)\n",
    "raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify target column\n",
    "target = \"label\"\n",
    "# Specify columns to remove\n",
    "columns_to_remove = [\"filename\", \"length\", target]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the data cleaning component we split the data into a test and train set and remove unnecesary columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seperate X (features) and y (target) from dataset\n",
    "y = raw.loc[:, target]\n",
    "X = raw.drop(columns_to_remove, axis=1)\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.3,\n",
    "    random_state=42,\n",
    ")\n",
    "# Use a named typle to keep track of the changes to train and test samples\n",
    "Samples = namedtuple(\"Samples\", [\"X_train\", \"y_train\", \"X_test\", \"y_test\"])\n",
    "# samples_raw is an instance of Samples, containing the raw samples\n",
    "# access train features by samples_raw.X_train\n",
    "samples_raw = Samples(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we filter out all genres except those specified by `target_pair`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out unneccesary data, only store songs with labels specified in target_pair\n",
    "train_filter = np.where(\n",
    "    (samples_raw.y_train == target_pair[0]) | (samples_raw.y_train == target_pair[1])\n",
    ")\n",
    "test_filter = np.where(\n",
    "    (samples_raw.y_test == target_pair[0]) | (samples_raw.y_test == target_pair[1])\n",
    ")\n",
    "X_train_filtered, X_test_filtered = (\n",
    "    samples_raw.X_train.iloc[train_filter],\n",
    "    samples_raw.X_test.iloc[test_filter],\n",
    ")\n",
    "y_train_filtered, y_test_filtered = (\n",
    "    samples_raw.y_train.iloc[train_filter],\n",
    "    samples_raw.y_test.iloc[test_filter],\n",
    ")\n",
    "# Convert target to binary int values, (genre_1, genre_2)->(0,1)\n",
    "y_train_filtered = np.where(y_train_filtered == target_pair[1], 1, 0)\n",
    "y_test_filtered = np.where(y_test_filtered == target_pair[1], 1, 0)\n",
    "# samples_filtered now contains the latest X, y train and test data\n",
    "samples_filtered = Samples(\n",
    "    X_train_filtered, y_train_filtered, X_test_filtered, y_test_filtered\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature Scaling and Selection**\n",
    "\n",
    "Here we manually select $8$ features to build the model on and then scale them to range between $[0,\\frac{\\pi}{2}]$. The selection can be automated with strategies like PCA or tree based methods using [sklearn pipelines](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html). Even though we just scale the data, the code is presented in such a way so that it's easy to add other pipeline steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify features to build model on\n",
    "features = [\n",
    "    \"mfcc2_var\",\n",
    "    \"mfcc3_var\",\n",
    "    \"mfcc4_var\",\n",
    "    \"mfcc5_var\",\n",
    "    \"mfcc7_var\",\n",
    "    \"mfcc8_var\",\n",
    "    \"mfcc11_mean\",\n",
    "    \"mfcc13_mean\",\n",
    "]\n",
    "X_train_selected = np.array(samples_filtered.X_train[features])\n",
    "X_test_selected = np.array(samples_filtered.X_test[features])\n",
    "\n",
    "samples_selected = Samples(\n",
    "    X_train_selected, samples_filtered.y_train, X_test_selected, samples_filtered.y_test\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Create a pipeline_list which will contain preprocessing steps\n",
    "pipeline_list = []\n",
    "# For now we only scale the data, but more complicated pipelines can be constructed with this pattern\n",
    "scaler = (\n",
    "    \"minmax\",\n",
    "    MinMaxScaler(feature_range=[0, np.pi / 2]),\n",
    ")\n",
    "pipeline_list.append(scaler)\n",
    "pipeline = Pipeline(pipeline_list)\n",
    "# Fit pipeline\n",
    "pipeline.fit(samples_selected.X_train, samples_selected.y_train)\n",
    "# Transform data\n",
    "X_train_tfd = pipeline.transform(samples_selected.X_train)\n",
    "X_test_tfd = pipeline.transform(samples_selected.X_test)\n",
    "samples_tfd = Samples(\n",
    "    X_train_tfd, samples_selected.y_train, X_test_tfd, samples_selected.y_test\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode data into a quantum state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def qubit_encoding(x, gate=cirq.rx):\n",
    "    circuit = cirq.Circuit()\n",
    "    for i, value in enumerate(x):\n",
    "        qubit = cirq.LineQubit(i)\n",
    "        circuit.append(gate(value).on(qubit))\n",
    "\n",
    "    return circuit\n",
    "\n",
    "\n",
    "X_train_encoded = tfq.convert_to_tensor(\n",
    "    [qubit_encoding(x) for x in samples_tfd.X_train]\n",
    ")\n",
    "X_test_encoded = tfq.convert_to_tensor([qubit_encoding(x) for x in samples_tfd.X_test])\n",
    "\n",
    "samples_encoded = Samples(\n",
    "    X_train_encoded, samples_tfd.y_train, X_test_encoded, samples_tfd.y_test\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build model\n",
    "\n",
    "Before building the model, we'll showcase some of the functionality through examples. For illustration purposes we use a simple $CR_z(\\theta)$ gate for convolutions and a CNOT for pooling. These are chosen arbitrarily, when using the tool the user can to send a function containing the sequence of gates constituting a convolution or pooling operation. This function may be built with any QML library such as `Cirq`, `Qiskit` or `Pennylane`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from cirq.contrib.svg import SVGCircuit\n",
    "\n",
    "# Default Convolution\n",
    "bits = (1, 2)\n",
    "symbols = sympy.symbols(\"x_0:2\")\n",
    "circuit = cirq.Circuit()\n",
    "q0, q1 = cirq.LineQubit(bits[0]), cirq.LineQubit(bits[1])\n",
    "circuit += cirq.rz(symbols[0]).on(q1).controlled_by(q0)\n",
    "print(\"Convolution unitary:\")\n",
    "SVGCircuit(circuit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bits = (1, 2)\n",
    "circuit = cirq.Circuit()\n",
    "q0, q1 = cirq.LineQubit(bits[0]), cirq.LineQubit(bits[1])\n",
    "circuit += cirq.CNOT(q0, q1)\n",
    "print(\"Pooling unitary:\")\n",
    "SVGCircuit(circuit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dynamic_qcnn import Qcnn_cirq as Qcnn_cirq\n",
    "from dynamic_qcnn import (\n",
    "    Qcnn,\n",
    "    Qfree,\n",
    "    Qconv,\n",
    "    Qpool,\n",
    "    Qdense,\n",
    "    binary_tree_r,\n",
    "    convert_graph_to_circuit_cirq,\n",
    "    plot_graph,\n",
    "    pretty_cirq_plot,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Reverse binary tree\n",
    "N = 8\n",
    "# level 1\n",
    "m1_1 = Qconv(1)\n",
    "m1_2 = Qpool(filter=\"outside\")\n",
    "# level 2\n",
    "m2_1 = m1_1 + m1_2\n",
    "# level 3\n",
    "m3_1 = Qfree(N) + m2_1 * int(np.log2(N))\n",
    "\n",
    "circuit, symbols = convert_graph_to_circuit_cirq(m3_1)\n",
    "# m3_1 + Qfree([1,3,5]) + Qconv(5)+m3_1)*4\n",
    "SVGCircuit(circuit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scale up the same model, and alternate architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cirq\n",
    "\n",
    "# Default pooling circuit\n",
    "def V(bits, symbols=None):\n",
    "    circuit = cirq.Circuit()\n",
    "    q0, q1 = cirq.LineQubit(bits[0]), cirq.LineQubit(bits[1])\n",
    "    circuit += cirq.rz(symbols[0]).on(q1).controlled_by(q0)\n",
    "    circuit += cirq.X(q0)\n",
    "    circuit += cirq.rx(symbols[1]).on(q1).controlled_by(q0)\n",
    "    return circuit\n",
    "\n",
    "\n",
    "# Default convolution circuit\n",
    "def U(bits, symbols=None):\n",
    "    circuit = cirq.Circuit()\n",
    "    q0, q1 = cirq.LineQubit(bits[0]), cirq.LineQubit(bits[1])\n",
    "    circuit += cirq.rx(symbols[0]).on(q0)\n",
    "    circuit += cirq.rx(symbols[1]).on(q1)\n",
    "    circuit += cirq.rz(symbols[2]).on(q0)\n",
    "    circuit += cirq.rz(symbols[3]).on(q1)\n",
    "    circuit += cirq.rz(symbols[4]).on(q1).controlled_by(q0)\n",
    "    circuit += cirq.rz(symbols[5]).on(q0).controlled_by(q1)\n",
    "    circuit += cirq.rx(symbols[6]).on(q0)\n",
    "    circuit += cirq.rx(symbols[7]).on(q1)\n",
    "    circuit += cirq.rz(symbols[8]).on(q0)\n",
    "    circuit += cirq.rz(symbols[9]).on(q1)\n",
    "    return circuit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Currently not implemented\n",
    "# #from dynamic_qcnn import Qcnn_cirq\n",
    "# m  = Qfree(8) + (Qconv(1) + Qpool(filter=\"inside\"))*3\n",
    "\n",
    "# readout = cirq.LineQubit(m.head.Q_avail[0])\n",
    "# circuit, symbols = convert_graph_to_circuit_cirq(m)\n",
    "\n",
    "# model = tf.keras.Sequential(\n",
    "#     [\n",
    "#         # The Qcnn layer returns the expected value of the readout gate, range [-1,1]. By default readout is criq.Z and the model determines\n",
    "#         # which qubit to measure based on the one that's left over\n",
    "#         Qcnn_cirq(circuit=circuit, symbols=symbols, readout=readout),\n",
    "#         # Convert expectation values to lie between 0 and 1\n",
    "#         tf.keras.layers.Rescaling(1.0 / 2, offset=0.5),\n",
    "#     ]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model.compile(\n",
    "#     optimizer=\"Adam\",\n",
    "#     loss=\"binary_crossentropy\",\n",
    "#     metrics=[tf.keras.metrics.BinaryAccuracy(threshold=0.5)],\n",
    "# )\n",
    "# # model.run_eagerly = True\n",
    "# model.fit(x=samples_encoded.X_train, y=samples_encoded.y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.summary()\n",
    "# print(model.trainable_variables)\n",
    "\n",
    "# qcnn_results = model.evaluate(samples_encoded.X_test, samples_encoded.y_test)\n",
    "# # results.append([f\"{s_c}_{s_p}_{pool_filter}\", qcnn_results])\n",
    "# print(qcnn_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_cirq",
   "language": "python",
   "name": "env_cirq"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
